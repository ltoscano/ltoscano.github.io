<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Machine Learning & Cognitive</title>
  <meta name="description" content="Lorenzo Toscano's Artificial Intelligence Articles and Projects">

  <script src="https://use.fontawesome.com/42ac583ec1.js"></script>

  <!-- Google Fonts loaded here depending on setting in _data/options.yml true loads font, blank does not-->
  
    <link href='//fonts.googleapis.com/css?family=Lato:400,400italic' rel='stylesheet' type='text/css'>
  

  <!-- Load up MathJax script if needed ... specify in /_data/options.yml file-->
  
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  

  <link rel="stylesheet" type="text/css" href="/css/tufte.css">
  <!-- <link rel="stylesheet" type="text/css" href="/css/print.css" media="print"> -->

  <link rel="canonical" href="https://ltoscano.github.com/">

  <link rel="alternate" type="application/rss+xml" title="Machine Learning & Cognitive" href="https://ltoscano.github.com/feed.xml" />

  <script src="/assets/jquery-1.12.4.min.js"></script>
  <script src="/assets/totop.min.js"></script>

  <style>
    .totop {
              position: fixed;
              bottom: 50px;
              right: 50px;
              cursor: pointer;
              display: none;
              background: #a05b7e;
              color: #fff;
              border-radius: 25px;
              height: 50px;
              line-height: 50px;
              padding: 0 30px;
              font-size: 18px;
      }
  </style>

</head>

  <body class="full-width">
    <a name="TopOfPage"></a>
<!--- Header and nav template site-wide -->
<header>
    <nav class="group">
	<a href="/"><img class="badge" src="/assets/img/badge_1.png" alt="CH"></a>
  <span class="blogtitle">Machine Learning & Cognitive - ApprendimentoAutomatico.it</span><br/>
  
    <a class="active" href="/">Blog</a>
  
  
  
    
    
    
  	
    
    
    
  	
    
    
    
  	
    
  	
    
    
		    
		      <a href="/resources/">Resources</a>
		    
	    
    
  	
    
    
		    
		      <a href="/about/">About</a>
		    
	    
    
  	
    
    
		    
		      <a href="/privacy/">Privacy & Cookie (ita)</a>
		    
	    
    
  	
	</nav>
</header>

    <article>
        <h1 class="content-listing-header sans">Articles</h1>
  <p>
  Welcome to my web pages! The tabs at the top lead to <em>projects</em>, <em>resources</em> about machine learning and cognitive computing, or info <em>about</em> me.  Here you'll find an occasional post on a topic that caught my interest...
</p>


  <ul class="content-listing ">
    
        <li class="listing">
          <hr class="slender">
          <a href="/articles/17/introduction-to-bitcoin-intuitions"><h3 class="contrast">Intuitions on the fly on Blockchain</h3></a>
          <br><span class="smaller">May, 2017</span>  <br/>
          <div><p><label for="mf-id-whatever" class="margin-toggle">⊕</label><input type="checkbox" id="mf-id-whatever" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/assets/img/blockchain.png" /><br />Image source: <a href="https://icons8.com/">Icons8</a>. <em>Distributed under <a href="https://creativecommons.org/licenses/by-nd/3.0/">Creative Commons Attribution-NoDerivs 3.0 Unported.</a></em></span>
An increasing number of articles suggest fascinating combinations of Blockchain and Machine Learning. It could be useful to introduce some intuitions about what is a blockchain, before venturing forth.</p>

<p>In the 2008 <a href="https://en.wikipedia.org/wiki/Bitcoin">Bitcoin</a> entered the market. It was a pioneering payment method and <strong>cryptocurrency</strong>.</p>

<p>The technology underlying Bitcoin is called <strong>Blockchain</strong>. Nowadays Bitcoin is the most important implementation of Blockchain. However, in the last 2 years many opportunities have emerged and Blockchain has assumed a central role in different contexts.</p>

<p>It is not simple to exactly explain how Blockchain works because it is a <a href="https://bitsonblocks.net/2015/09/09/a-gentle-introduction-to-blockchain-technology/">combination of different technologies</a>. More appropriately, Blockchain is an <strong>ecosystem</strong> where different technologies, approaches and theories converge.</p>

</div>
        </li>
    
        <li class="listing">
          <hr class="slender">
          <a href="/articles/17/hype-cycle-e-apprendimento-automatico-in-che-fase-siamo"><h3 class="contrast">Hype cycle e Apprendimento Automatico: in che fase siamo?</h3></a>
          <br><span class="smaller">April, 2017</span>  <br/>
          <div><p><label for="mf-id-whatever" class="margin-toggle">⊕</label><input type="checkbox" id="mf-id-whatever" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/assets/img/1118px-Gartner_Hype_Cycle.svg.png" /><br />Image source: <a href="https://commons.wikimedia.org/wiki/File:Gartner_Hype_Cycle.svg">Wikimedia</a>. <em>Distributed under <a href="https://en.wikipedia.org/wiki/GNU_Free_Documentation_License">GNU Free Documentation License</a></em></span>
Ogni trend tecnologico si sviluppa attraverso una successione di fasi che ne caratterizza il processo di maturazione: dall’emersione alla sua accettazione. Tale processo è sempre accompagnato da un “<strong>buzzing tecnologico</strong>” che solitamente esplode nelle fasi iniziali di maggiore “illusione” per poi rimodularsi progressivamente in funzione dell’accettazione da parte del pubblico. Semplificando, il ben noto <a href="https://en.wikipedia.org/wiki/Hype_cycle">hype cycle</a> (<strong>ciclo dell’esagerazione</strong>) di Gartner potrebbe essere considerato come una metodologia che ci aiuta a riassumere graficamente lo stato del buzzing che avvolge una grande varietà di trend tecnologici.</p>

</div>
        </li>
    
        <li class="listing">
          <hr class="slender">
          <a href="/articles/17/emotions-detection-via-facial-expressions-with-python-opencv"><h3 class="contrast">Emotions Detection Via Facial Expressions with python & OpenCV</h3></a>
          <br><span class="smaller">January, 2017</span>  <br/>
          <div><p><label for="mf-id-whatever" class="margin-toggle">⊕</label><input type="checkbox" id="mf-id-whatever" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/assets/img/Universal_emotions7.jpg" /><br /></span>
In this tutorial I aim to quench a subset of your machine learning thirst; And for what other reason would you be here? This tutorial is based on training a computer to recognize not just your face but the emotion expressed on it. How cool is that? Imagine walking into your home after a long day of work, and your computer immediately knows what kind of therapeutic music to play based on how you are feeling, or when you are driving the car onboard computer is able to assess your ability to drive based on your emotions.</p>

</div>
        </li>
    
        <li class="listing">
          <hr class="slender">
          <a href="/articles/17/introduction-to-gradient-boosted-trees-and-xgboost-hyperparameters-tuning-with-python"><h3 class="contrast">Introduction to gradient-boosted trees and XGBoost hyperparameters tuning (with python)</h3></a>
          <br><span class="smaller">January, 2017</span>  <br/>
          <div><p><label for="mf-id-whatever" class="margin-toggle">⊕</label><input type="checkbox" id="mf-id-whatever" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/assets/img/ensembletree.png" /><br /></span>
XGBoost model is a supervised machine learning algorithm that takes in the training data and constructs a model that predicts the outcome of new data instances.</p>

<p>XGBoost has gained a lot of popularity in the machine learning community due to its ability to train versatile model with speed and quality performance. It’s an implementation of <strong>gradient boosted decision trees</strong> which are constructed for speed and performance.</p>

<p>For an in-depth introduction visit this link for <a href="http://xgboost.readthedocs.io/en/latest/model.html">more technical details</a>.</p>

<p>Here we cover a gentle introduction of XGBoost model using python scikit-learn package.</p>

<p>By the end of this tutorial you will have learnt:</p>

<p>XGBoost installation for python use</p>

<p>XGBoost data preparation and model training</p>

<p>XGBoost model prediction</p>

<p>XGBoost hyperparameters tuning</p>

</div>
        </li>
    
        <li class="listing">
          <hr class="slender">
          <a href="/articles/16/introduction-to-decision-trees-with-bigml-a-step-by-step-guide"><h3 class="contrast">Introduction to decision trees with BigML: a step by step guide </h3></a>
          <br><span class="smaller">December, 2016</span>  <br/>
          <div><p><label for="mf-id-whatever" class="margin-toggle">⊕</label><input type="checkbox" id="mf-id-whatever" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/assets/img/bigml.png" /><br /></span>
The discussion on machine learning is the buzz word in the current tech tectonic waves. It’s all amber-hot as the machines are nearly on the verge of learning to do things and react to the environment around them in more <a href="https://www.newscientist.com/article/2110522-googles-neural-networks-invent-their-own-encryption/">human-like-unsupervised-design</a>.</p>

<p>Machine learning is a field of neuro-computational studies, in which scientists work towards instilling learning capabilities in a computer memory. This is all possible through implementation of a set of supervised or unsupervised rules referred to as algorithms. The most popular machine learning algorithms are artificial neural networks, support vector machines, k-nearest neighbors and <strong>decision trees</strong>. We will discuss the decision trees in this context.</p>

</div>
        </li>
    
        <li class="listing">
          <hr class="slender">
          <a href="/articles/16/machine-learning-best-cheat-sheets-one-page"><h3 class="contrast">Machine Learning: the best cheat sheets in one page</h3></a>
          <br><span class="smaller">December, 2016</span>  <br/>
          <div><p><label for="mf-id-whatever" class="margin-toggle">⊕</label><input type="checkbox" id="mf-id-whatever" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/assets/img/human-1211467_1280-e1480808939595.png" /><br /></span>
Squeezed into a set of short tips and schemes, a cheat sheet is not only a source for visual inspiration but also a quick way to learn something new, as well as to refresh your knowledge about any particular subject.</p>

</div>
        </li>
    
        <li class="listing">
          <hr class="slender">
          <a href="/articles/16/stream-processing-and-analysis-to-move-within-the-apache-ecosystem"><h3 class="contrast">Understanding Apache Ecosystem: stream processing</h3></a>
          <br><span class="smaller">November, 2016</span>  <br/>
          <div><p><label for="mf-id-whatever" class="margin-toggle">⊕</label><input type="checkbox" id="mf-id-whatever" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/assets/img/apache-ecosystem.jpg" /><br /></span>
In this article I will show how a normal big data/machine learning project progresses, taking in account the <strong>stream processing</strong> and analysis part. I will try to functionally position a wide variety of Apache projects such as Sqoop, Flume, Kafka, Hadoop, Storm, Spark, Samza, Flink, Beam, Oozie, Thrift.</p>

</div>
        </li>
    
        <li class="listing">
          <hr class="slender">
          <a href="/articles/16/gentle-introduction-to-tensorflow-with-python-and-rnn"><h3 class="contrast">A gentle introduction to TensorFlow with python (and RNN)</h3></a>
          <br><span class="smaller">November, 2016</span>  <br/>
          <div><p><label for="mf-id-whatever" class="margin-toggle">⊕</label><input type="checkbox" id="mf-id-whatever" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/assets/img/tensorflowpython.png" /><br /></span>
My quick and dirty introduction to TensorFlow.</p>

</div>
        </li>
    
        <li class="listing">
          <hr class="slender">
          <a href="/articles/16/riconoscimento-vocale-analisi-testo-watson-developer-cloud-python-sdk"><h3 class="contrast">Riconoscimento vocale e analisi di testo non strutturato con Watson Developer Cloud Python SDK</h3></a>
          <br><span class="smaller">November, 2016</span>  <br/>
          <div><p><label for="mf-id-whatever" class="margin-toggle">⊕</label><input type="checkbox" id="mf-id-whatever" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/assets/img/blue-robot-vector-art-e1478100652986.png" /><br /></span>
In questo post illustro come: estrarre <strong>tracce audio</strong> da filmati (usando, per esempio, YouTube), eseguire una <strong>conversione del parlato</strong> in testo (<em>speech to text</em>), estrarre <strong>conoscenza dal testo non strutturato della trascrizione</strong>.</p>

</div>
        </li>
    
        <li class="listing">
          <hr class="slender">
          <a href="/articles/16/image-recognition-tutorial-python-mxnet-deep-convolutional"><h3 class="contrast">Image recognition tutorial in Python/MXNet using deep convolutional</h3></a>
          <br><span class="smaller">October, 2016</span>  <br/>
          <div><p><label for="mf-id-whatever" class="margin-toggle">⊕</label><input type="checkbox" id="mf-id-whatever" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/assets/img/catimagecnn.png" /><br /></span>
I would like to introduce in this post some specific CNN implementations which are able to offer a cognitive image processing that is very close to the state of the art. The exemplary code is based on the use of <a href="http://mxnet.incubator.apache.org/">MXNet</a> framework combined with the Python language.</p>

<p>MXNet is an open source project, distributed under the Apache License Version 2.0, a result of the research and development groups’ collaboration, belonging to important institutions such as CMU, NYU, NUS and MIT. It is a DMLC project. DMLC is a group of companies, laboratories and universities engaged in projects which are contributing from many years in defining the leading edge in the field of machine learning.</p>

</div>
        </li>
    
        <li class="listing">
          <hr class="slender">
          <a href="/articles/16/exploring-tweets-python-based-demonstrator"><h3 class="contrast">Exploring Tweets: a python-based demonstrator</h3></a>
          <br><span class="smaller">August, 2016</span>  <br/>
          <div><p><label for="mf-id-whatever" class="margin-toggle">⊕</label><input type="checkbox" id="mf-id-whatever" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/assets/img/social_networking.png" /><br /></span>
Tools based on visual representations of social networks are important to understand network data and convey the result of the analysis. Visualization facilitates qualitative interpretation of network data. This kind of tools helps us to identify key influencers, contents, and to focalize attention on interesting users optimizing our time.</p>

</div>
        </li>
    
        <li class="listing">
          <hr class="slender">
          <a href="/articles/16/identificazione-di-oggetti-in-immagini-con-convolutional-neural-network-python-e-mxnet"><h3 class="contrast">Identificazione di oggetti in immagini con Convolutional Neural Network, Python e MXNet</h3></a>
          <br><span class="smaller">August, 2016</span>  <br/>
          <div><p><label for="mf-id-whatever" class="margin-toggle">⊕</label><input type="checkbox" id="mf-id-whatever" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/assets/img/catimagecnn.png" /><br /></span>
Ci sono molti strumenti che permettono di identificare un oggetto in un’immagine, come ad esempio il modello <em>bag of visual words</em>, tramite i descrittori di feature SIFT (<em>scale-invariant feature transform</em>) o SURF (<em>speeded up robust feature</em>), oppure l’utilizzo delle macchine a vettori di supporto (SVM, <em>support vector machine</em>); tuttavia, in questi ultimi anni, le reti neurali profonde (<strong>DNN</strong>, <em>deep neural networks</em>) hanno contribuito con un nuovo impulso alla ricerca e sono, pertanto, sempre più utilizzate. Infatti, l’abilità delle DNN nell’apprendere, a partire da grandi insiemi di esempi, funzioni complesse, non-lineari e ad alta dimensionalità, le rende perfette candidate per i compiti di riconoscimento di immagini. Un tipo particolare di DNN sono le <strong>reti neurali convoluzionali</strong> (<strong>CNN</strong>, <em>convolutional neural networks</em>) usate con grande successo per problemi di riconoscimento automatico di pattern bidimensionali come la rivelazione di oggetti, facce e loghi nelle immagini. In questo post introduco alcune specifiche implementazioni di CNN in grado di offrire un’elaborazione cognitiva delle immagini che è molto prossima allo stato dell’arte. Il codice esemplificativo è basato sull’impiego del framework <a href="http://mxnet.incubator.apache.org/">MXNet</a> in combinazione con il linguaggio Python.</p>

</div>
        </li>
    
        <li class="listing">
          <hr class="slender">
          <a href="/articles/16/filtraggio-stop-word-nodo-custom-knime-python-script"><h3 class="contrast">Filtraggio delle stop word con nodo custom in Knime</h3></a>
          <br><span class="smaller">August, 2016</span>  <br/>
          <div><p><label for="mf-id-whatever" class="margin-toggle">⊕</label><input type="checkbox" id="mf-id-whatever" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/assets/img/stoplist-knime-e1472482793929.png" /><br /></span>
Un’operazione di filtraggio importante, nella processazione dei dataset, consiste nella rimozione delle stop word. In questo post propongo due esempi di implementazione di tale filtraggio basati nell’ambiente Knime. Il secondo esempio, in particolare, fonde la sintesi e la ricchezza di Python con la comodità di impiego di Knime: una coppia eccezionale, come vedremo.</p>

</div>
        </li>
    
        <li class="listing">
          <hr class="slender">
          <a href="/articles/16/come-generare-un-corpus-a-tema-in-italiano-da-wikipedia-pochi-secondi"><h3 class="contrast">Come generare un corpus, a tema, in Italiano, da Wikipedia e… in pochi secondi</h3></a>
          <br><span class="smaller">August, 2016</span>  <br/>
          <div><p><label for="mf-id-whatever" class="margin-toggle">⊕</label><input type="checkbox" id="mf-id-whatever" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/assets/img/scraping-1-e1472407353263.png" /><br /></span>
Talvolta può essere necessario operare, per scopi dimostrativi o altre ragioni, su un corpus di dimensioni modeste consistente di documenti redatti in una lingua specifica (non necessariamente l’Inglese) e calati su argomenti particolari. In questo post propongo un notebook ipython con il codice per generare un corpus siffatto riducendo al minimo le complicazioni tecniche e i tempi di produzione. La sorgente che utilizziamo per i contenuti è Wikipedia.</p>

</div>
        </li>
    
        <li class="listing">
          <hr class="slender">
          <a href="/articles/16/trasformazioni-con-riduzione-dimensionalita"><h3 class="contrast">Fondamenti: trasformazioni con riduzione di dimensionalità</h3></a>
          <br><span class="smaller">July, 2016</span>  <br/>
          <div><p><label for="mf-id-whatever" class="margin-toggle">⊕</label><input type="checkbox" id="mf-id-whatever" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/assets/img/introtolda.png" /><br /></span>
Caro lettore, in questo post, con una buona dose di spregiudicatezza (data la complessità della materia), ti propongo un “volo ad alta quota” sui territori particolarmente estesi e variegati del topic modeling. Lo scopo del post è introdurre le intuizioni che sono dietro ai vari modelli con brevi digressioni finalizzate esclusivamente all’introduzione di nozioni basilari. Ogni approfondimento è demandato alla tua sensibilità e per questo fornisco un’estesa quantità di link a risorse che possono aiutarti a focalizzare la tua attenzione. La matematica dietro ai modelli è appena accennata e volutamente semplificata, per fornire un’idea dei concetti fondanti e darti una maggiore consapevolezza dei parametri impostabili quando utilizzerai le implementazioni dei modelli. L’obiettivo della serie Fondamenti è quello di supportarti nella costruzione di un quadro operativo, mediante l’impiego trasversale di una estesa varietà di risorse di programmazione e analisi dei dati,  anche il presente post non si sottrae a questo obiettivo. Buona lettura.</p>

</div>
        </li>
    
        <li class="listing">
          <hr class="slender">
          <a href="/articles/16/schemi-di-rappresentazione-e-trasformazioni"><h3 class="contrast">Fondamenti: schemi di rappresentazione e trasformazioni</h3></a>
          <br><span class="smaller">July, 2016</span>  <br/>
          <div><p><label for="mf-id-whatever" class="margin-toggle">⊕</label><input type="checkbox" id="mf-id-whatever" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/assets/img/3D-query-with-documents-in-vector-space.png" /><br /></span>
Il contenuto seguente rappresenta il prosieguo di quanto esposto in <a href="/articles/16/selezione-attributi-e-rappresentazione-dei-documenti">Fondamenti: selezione attributi e rappresentazione dei documenti</a>.</p>

<p>In sintesi: i documenti nel corpus sono rappresentati come vettori in uno spazio M-dimensionale, con M pari al numero di attributi selezionati e indicizzati nel vocabolario V. Ad ogni attributo è associato un <strong>peso</strong>. Numerose sono le metriche di pesatura utilizzabili per calcolare il valore dei pesi degli attributi.</p>

<p>Per esempio, nello schema di rappresentazione BOW (<em>bag of words</em>), il peso wij è un numero intero che esprime la frequenza statistica (cioè il numero di occorrenze) dell’attributo i-esimo nel documento j-esimo.</p>

<p>In questo post tratteremo in modo specifico di altre metriche di pesatura che realizzano delle <strong>trasformazioni pari-dimensionali</strong> ossia delle variazione delle rappresentazioni vettoriali con mantenimento nel numero di attributi M.</p>

</div>
        </li>
    
        <li class="listing">
          <hr class="slender">
          <a href="/articles/16/causalita-dati-apprendimento-automatico"><h3 class="contrast">Causalità, dati e apprendimento automatico</h3></a>
          <br><span class="smaller">July, 2016</span>  <br/>
          <div><p><label for="mf-id-whatever" class="margin-toggle">⊕</label><input type="checkbox" id="mf-id-whatever" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/assets/img/computer-comic.png" /><br /></span>
L’apprendimento automatico include una varietà di algoritmi e metodologie il cui fine è la modellazione delle variazioni di una o più grandezze assunte come <strong>variabili dipendenti</strong> (o esplicative) in funzione delle variazioni di altre grandezze dette <strong>variabili indipendenti</strong>.</p>

<p>Ogni modello è costruito a partire dai <strong>dati</strong>. I dati sono generalmente un sottoinsieme dei valori ammissibili delle grandezze in esame e sono sempre misurati sotto <strong>specifiche condizioni operative</strong> (che dovrebbero essere sufficientemente rappresentative di ciò che si vuole analizzare).</p>

<p>Il paradigma classico della programmazione del software prevede che, partendo dalla conoscenza dei dati di input, si debba poi codificare con un linguaggio di programmazione (p.e. Python o qualsiasi altro possiamo immaginare) il processo di trasformazione dell’input nell’output desiderato. I meccanismi di causalità che regolano la trasformazioni degli ingressi nelle uscite devono quindi essere ben noti al programmatore che è chiamato ad esprimerli in forma algoritmica.</p>

<p>Diversamente, il paradigma di programmazione che sottende ai sistemi di apprendimento automatico non richede la <strong>codifica esplicita (e manuale!) dei meccanismi di causalità</strong> e sposta il focus esclusivamente sui dati. Nei software di apprendimento automatico, le causalità tra i dati sono dedotte in modo approssimativo ed automatico (secondo approcci matematici specifici per ogni algoritmo di ML e spesso iterativi) e sono implicitamente codificate in parametri che contribuiscono al funzionamento del modello stesso (p.e. coefficienti di polinomi, etc..).</p>

</div>
        </li>
    
        <li class="listing">
          <hr class="slender">
          <a href="/articles/16/introduzione-a-gephi-in-11-passi"><h3 class="contrast">Introduzione a Gephi in 11 passi</h3></a>
          <br><span class="smaller">July, 2016</span>  <br/>
          <div><p><label for="mf-id-whatever" class="margin-toggle">⊕</label><input type="checkbox" id="mf-id-whatever" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/assets/img/Social_Network_Analysis_Visualization.png" /><br />Image source: <a href="https://commons.wikimedia.org/wiki/File:Social_Network_Analysis_Visualization.png">Wikimedia</a>. <em>Distributed under <a href="https://en.wikipedia.org/wiki/GNU_Free_Documentation_License">GNU Free Documentation License</a></em></span>
Gephi è un visualizzatore interattivo e una piattaforma di esplorazione per tutti i tipi di reti e sistemi complessi, dinamici e grafi gerarchici. E’ disponibile per Linux, Mac e Windows. E’ gratuito e open-source. Può essere scaricato dalla pagina <a href="https://gephi.org/users/download/">Download</a>.
Gephi è stato usato in una serie di progetti di ricerca in ambito universitario, giornalistico e in vari altri campi, per esempio per visualizzare le connessioni globali ai contenuti del New York Times o per esaminare la rete di traffico su Twitter in occasioni di disordini sociali, ma anche per altre tematiche solitamente oggetto di analisi di rete.</p>

</div>
        </li>
    
        <li class="listing">
          <hr class="slender">
          <a href="/articles/16/selezione-attributi-e-rappresentazione-dei-documenti"><h3 class="contrast">Fondamenti: selezione attributi e rappresentazione dei documenti</h3></a>
          <br><span class="smaller">July, 2016</span>  <br/>
          <div><p><label for="mf-id-whatever" class="margin-toggle">⊕</label><input type="checkbox" id="mf-id-whatever" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/assets/img/keywordsmagnify.jpg" /><br /></span>
Questo post è il primo di una serie denominata “Fondamenti”. L’obiettivo della serie è fornire una panoramica delle principali tecniche utilizzate per estrarre automaticamente conoscenza da testo non strutturato, come pagine web, email, forum e documenti in generale.</p>

<p>Il focus principale è sul topic modeling, ossia l’approccio semantico per <strong>identificare gli argomenti trattati in documenti, attraverso l’analisi della distribuzione delle parole</strong>. Il topic modeling è una delle tante applicazioni del text mining<label for="1" class="margin-toggle sidenote-number"></label><input type="checkbox" id="1" class="margin-toggle" /><span class="sidenote">Il <strong>data mining</strong> estrae sapere o conoscenza a partire da grandi quantità di dati, attraverso metodi automatici o semi-automatici. Il <strong>text mining</strong> o text data mining è una forma particolare di data mining dove i dati sono costituiti da testi scritti in linguaggio naturale, quindi da documenti “destrutturati”. </span> e si fonda su algoritmi di apprendimento che suddividono la collezione di documenti in raggruppamenti ciascuno facente riferimento ad un certo <strong>topic</strong> o <strong>argomento in senso generale</strong>. L’individuazione dei raggruppamenti avviene in modo automatico senza ausilio di addestramenti basati su esempi e quindi senza una preventiva supervisione da parte dell’uomo: il topic modeling rientra pertanto nella classe dei <strong>metodi di apprendimento non supervisionati su dati testuali</strong>.</p>

</div>
        </li>
    
  </ul>

    </article>
    <span class="print-footer">Machine Learning & Cognitive - lorenzo toscano</span>
    <footer>
  <hr class="slender">
  <ul class="footer-links">
    <li><a href="mailto:lorenzo.toscano@gmail.com"><span class="icon-mail"></span></a></li>
    
      <li>
        <a href="//www.twitter.com/BEmatic"><span class="icon-twitter"></span></a>
      </li>
    
      <li>
        <a href="//www.linkedin.com/in/lorenzotoscano"><span class="icon-linkedin"></span></a>
      </li>
    
      <li>
        <a href="//github.com/ltoscano"><span class="icon-github"></span></a>
      </li>
    
      <li>
        <a href="//www.scoop.it/t/knowmatic"><span class="icon-bullhorn"></span></a>
      </li>
    
      <li>
        <a href="/feed"><span class="icon-feed"></span></a>
      </li>
    
  </ul>
<div class="credits">
<span>&copy; 2018 &nbsp;&nbsp;LORENZO TOSCANO</span></br> <br>
<!--<span>This site created with the <a href="//github.com/clayh53/tufte-jekyll">Tufte theme for ApprendimentoAutomatico.it </a> in <a href="//jekyllrb.com">Jekyll</a>.</span> -->
</div>
</footer>
<div class="totop"><i class="fa fa-angle-up"></i> To Top</div>
<script>
      $('.totop').tottTop({
          scrollTop: 100
      });
</script>
<!--Start Cookie Script--> <script type="text/javascript" charset="UTF-8" src="//cookie-script.com/s/f67066386a32612237b658624241e0af.js"></script> <!--End Cookie Script-->

  </body>
</html>
