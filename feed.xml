<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning &amp; Cognitive</title>
    <description>Lorenzo Toscano's Artificial Intelligence Articles and Projects</description>
    <link>https://ltoscano.github.com/</link>
    <atom:link href="https://ltoscano.github.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 24 Jan 2018 08:50:12 -0500</pubDate>
    <lastBuildDate>Wed, 24 Jan 2018 08:50:12 -0500</lastBuildDate>
    <generator>Jekyll v3.6.2</generator>
    
      <item>
        <title>Amazon SageMaker con Microsoft CNTK/Keras</title>
        <description>&lt;p&gt;&lt;label for=&quot;mf-id-cntk_k_aws&quot; class=&quot;margin-toggle&quot;&gt;⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;mf-id-cntk_k_aws&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;img class=&quot;fullwidth&quot; src=&quot;/assets/img/cntk_k_aws.jpg&quot; /&gt;&lt;br /&gt;&lt;em&gt;I marchi sono di proprietà dei legittimi proprietari.&lt;/em&gt;&lt;/span&gt;
&lt;a href=&quot;https://aws.amazon.com/it/sagemaker/&quot;&gt;SageMaker&lt;/a&gt; è l’ambiente di Amazon che agevola la costruzione e distribuzione di modelli Machine/Deep Learning. Sostanzialmente è un servizio gestito della piattaforma &lt;a href=&quot;https://aws.amazon.com/it/&quot;&gt;AWS&lt;/a&gt; che agevola l’adozione di un paradigma di design &amp;amp; deploy basato su containerizzazione &lt;a href=&quot;https://www.docker.com&quot;&gt;Docker&lt;/a&gt;, packaging di web service su &lt;em&gt;lightweight serving stack&lt;/em&gt; come Nginx + Gunicorn + Flask e diverse altre amenità.&lt;/p&gt;

&lt;p&gt;&lt;label for=&quot;mf-id-whatever&quot; class=&quot;margin-toggle&quot;&gt;⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;mf-id-whatever&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;img class=&quot;fullwidth&quot; src=&quot;/assets/img/stack.png&quot; /&gt;&lt;br /&gt;Serving stack utilizzato in SageMaker. &lt;em&gt;Nginx è il server HTTP e reverse proxy, open source e ad alte prestazioni, noto per le sue elevate prestazioni, stabilità, ricco set di funzioni, semplicità di configurazione e basso consumo di risorse. Nginx assolve il ruolo di server di buffering di interfaccia. Green Unicorn (gunicorn) è un server HTTP/&lt;a href=&quot;https://it.wikipedia.org/wiki/Web_Server_Gateway_Interface&quot;&gt;WSGI&lt;/a&gt; (porting del progetto Ruby Unicorn) con bilanciamento del carico tramite pre-fork e socket condivisi. &lt;a href=&quot;https://goo.gl/zkiEux&quot;&gt;Flask&lt;/a&gt; è un framework scritto in Python, basato su librerie altamente performanti per la gestione del protocollo WSGI e il templating.&lt;/em&gt;&lt;/span&gt;&lt;!--more--&gt;
In questo articolo propongo un approccio per il deployment di un modello custom ML/DL basato sulla libreria &lt;a href=&quot;https://github.com/Microsoft/CNTK&quot;&gt;Microsoft CNTK&lt;/a&gt;, sfruttando le funzionalità di SageMaker. Assumo che il lettore abbia già una conoscenza operativa di Docker.&lt;/p&gt;

&lt;p&gt;Il modello di distribuzione di SageMaker prevede l’incapsulamento dei modelli ML/DL in immagini Docker. Semplificando, da un’immagine, è dinamicamente generato un container che è eseguito automaticamente su un’istanza EC2&lt;label for=&quot;sh-id-ec2&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sh-id-ec2&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;&lt;a href=&quot;https://aws.amazon.com/it/ec2/&quot;&gt;Amazon Elastic Computer Cloud&lt;/a&gt; &lt;/span&gt; dedicata e ottimizzata per l’impiego ML&lt;label for=&quot;sh-mlistance&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sh-mlistance&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;&lt;a href=&quot;https://aws.amazon.com/sagemaker/pricing/instance-types/&quot;&gt;Amazon SageMaker ML Instance Types&lt;/a&gt; &lt;/span&gt;. Il modello è pacchettizzato in modo da essere accessibile attraverso una RESTful API che è automaticamente collegata ad un endpoint HTTPS in grado di offrire un punto di contatto robusto e scalabile verso il modo esterno. Questo tipo di approccio ben si coniuga con uno &lt;strong&gt;stile architetturale a microservizi&lt;/strong&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Lo stile architetturale a microservizi è un approccio allo sviluppo di una singola applicazione come insieme di piccoli servizi, ciascuno dei quali viene eseguito da un proprio processo e comunica con un meccanismo snello, spesso una HTTP API. &lt;em&gt;&lt;a href=&quot;https://martinfowler.com&quot;&gt;Martin Fowler&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;SageMaker offre anche un insieme di immagini Docker preconfigurate in cui sono incapsulati framework ML/DL e implementazioni di algoritmi base. Utilizzando queste immagini è possibile costruire rapidamente semplici modelli facilmente distribuibili.&lt;/p&gt;

&lt;h2 id=&quot;creazione-di-una-notebook-instance-su-sagemaker&quot;&gt;Creazione di una &lt;em&gt;notebook instance&lt;/em&gt; su SageMaker&lt;/h2&gt;

&lt;p&gt;Il primo passo consiste nell’accedere alla console di SageMaker e da questa attivare (o creare) una &lt;strong&gt;notebook instance&lt;/strong&gt;. A seguire, facendo click su &lt;code class=&quot;highlighter-rouge&quot;&gt;Open&lt;/code&gt;, accediamo all’istanza &lt;strong&gt;Jupyter&lt;/strong&gt;. Dalla finestra di Jupyter, facciamo click su &lt;code class=&quot;highlighter-rouge&quot;&gt;New&lt;/code&gt; e apriamo una finestra &lt;code class=&quot;highlighter-rouge&quot;&gt;Terminal&lt;/code&gt; nel browser, ossia una shell sulla nostra istanza EC2. Siamo loggati come utenti &lt;code class=&quot;highlighter-rouge&quot;&gt;ec2-user&lt;/code&gt;.&lt;label for=&quot;mf-id-sageinstance&quot; class=&quot;margin-toggle&quot;&gt;⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;mf-id-sageinstance&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;img class=&quot;fullwidth&quot; src=&quot;/assets/img/sagemaker_2.png&quot; /&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Dalla linea di comando digitiamo &lt;code class=&quot;highlighter-rouge&quot;&gt;cd SageMaker&lt;/code&gt;, quindi cloniamo (&lt;code class=&quot;highlighter-rouge&quot;&gt;git clone&lt;/code&gt;) il package git &lt;a href=&quot;https://github.com/ltoscano/CNTK_KERAS_SAGEMAKER.git&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;CNTK_KERAS_SAGEMAKER&lt;/code&gt;&lt;/a&gt; che ho appositamente predisposto per agevolare le prossime operazioni.&lt;/p&gt;

&lt;p&gt;Digitiamo &lt;code class=&quot;highlighter-rouge&quot;&gt;cd CNTK_KERAS_SAGEMAKER/container&lt;/code&gt; per spostarci all’interno del package appena clonato. Per semplicità, chiamiamo questo punto di accesso &lt;strong&gt;cartella base&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;La cartella base è così organizzata:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;build_and_push_to_ecr.sh&lt;/code&gt;: lo script file per la generazione dell’immagine e il pushing sul registro Docker ECR&lt;label for=&quot;sn-id-ecr&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sn-id-ecr&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;&lt;a href=&quot;https://aws.amazon.com/it/ecr/&quot;&gt;Amazon Elastic Container Registry&lt;/a&gt; &lt;/span&gt;;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Dockefile&lt;/code&gt;: il file di testo contenente le istruzioni necessarie per creare una nuova immagine basata su Microsoft CNTK (versione 2.3 con supporto per Py27 e CPU&lt;label for=&quot;sn-id-ecr&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sn-id-ecr&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;Il file può essere facilmente modificato per selezionare una versione più recente di CNTK sia con supporto GPU sia Py2 o Py3. Per ulteriori informazioni consultare la pagina &lt;a href=&quot;https://docs.microsoft.com/en-us/cognitive-toolkit/CNTK-Docker-Containers&quot;&gt;CNTK Docker Containers&lt;/a&gt;. &lt;/span&gt;);&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;keras.json&lt;/code&gt;: il file di testo contente le impostazioni per il framework Keras (versione 2.0.6 o superiore) incluso nell’immagine. Queste impostazioni consentono l’integrazione di Keras con la libreria CNTK. Il file è automaticamente caricato all’interno dell’immagine durante la fase di &lt;em&gt;building&lt;/em&gt;;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;context&lt;/code&gt;: la cartella che contiene i file dati e di configurazione per la creazione del modello;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;setup&lt;/code&gt;: la cartella che contiene i file script che permettono a SageMaker di istanziare un container e attivare un modello richiamando le funzioni di addestramento e predizione;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;evaluation&lt;/code&gt;: la cartella con file dati esemplificativi e i notebook jupyter che illustrano come utilizzare il modello basato su CNTK da un notebook in SageMaker.&lt;/p&gt;

&lt;h2 id=&quot;test-in-locale&quot;&gt;Test in locale&lt;/h2&gt;

&lt;p&gt;Partiamo con l’esame della cartella &lt;code class=&quot;highlighter-rouge&quot;&gt;context&lt;/code&gt;. La cartella è utilizzata esclusivamente per finalità di test in locale (ossia prima di operare su ECR e con SageMaker) e replica al suo interno una gerarchia che riflette esattamente il funzionamento a regime di SageMaker. In &lt;code class=&quot;highlighter-rouge&quot;&gt;input&lt;/code&gt;, carichiamo il file json &lt;code class=&quot;highlighter-rouge&quot;&gt;hyperparameters.json&lt;/code&gt; che contiene i parametri di configurazione del nostro modello (imposteremo parametri simili anche attraverso SageMaker). Sempre in &lt;code class=&quot;highlighter-rouge&quot;&gt;input&lt;/code&gt;, in apposita sottocartella, carichiamo i file CSV &lt;code class=&quot;highlighter-rouge&quot;&gt;trainset.csv&lt;/code&gt; e &lt;code class=&quot;highlighter-rouge&quot;&gt;testset.csv&lt;/code&gt; contenenti rispettivamente training e testing set, per l’addestramento del modello. Infine, le sottocartelle &lt;code class=&quot;highlighter-rouge&quot;&gt;model&lt;/code&gt; e &lt;code class=&quot;highlighter-rouge&quot;&gt;output&lt;/code&gt; sono utilizzate per il salvataggio del modello addestrato (pesi e architettura) e per logging. A differenza della cartella di configurazione, il popolamento delle cartelle &lt;code class=&quot;highlighter-rouge&quot;&gt;model&lt;/code&gt; e &lt;code class=&quot;highlighter-rouge&quot;&gt;output&lt;/code&gt; è automatico, a valle della fase di addestramento del modello.&lt;/p&gt;

&lt;p&gt;Per testare in modalità locale il funzionamento del container e del modello in esso incapsulato, è necessario spostarsi nella cartella base e creare un’immagine Docker locale usando il comando:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  docker build -t cntkdemo .
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Dopo la creazione dell’immagine &lt;code class=&quot;highlighter-rouge&quot;&gt;cntkdemo&lt;/code&gt; è possibile spostarsi nella cartella &lt;code class=&quot;highlighter-rouge&quot;&gt;evaluation&lt;/code&gt; e digitare uno dei seguenti comandi:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;./run_local.sh train&lt;/code&gt;: per istanziare il modello ed eseguire il training;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;./run_local.sh serve&lt;/code&gt;: per attivare il modello in modalità &lt;em&gt;serving&lt;/em&gt; (in attesa di richieste);&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;./predict.py eval_data.csv&lt;/code&gt;: per richiedere una predizione (p.e. usando un file di dati di validazione). Questo script richiede che un’istanza del modello sia funzionante in modalità &lt;em&gt;serving&lt;/em&gt; (vedi punto precedente) in una finestra &lt;code class=&quot;highlighter-rouge&quot;&gt;Terminal&lt;/code&gt; dedicata. Nella cartella &lt;code class=&quot;highlighter-rouge&quot;&gt;evaluation&lt;/code&gt; sono anche memorizzati i file &lt;code class=&quot;highlighter-rouge&quot;&gt;eval_data.csv&lt;/code&gt; ed &lt;code class=&quot;highlighter-rouge&quot;&gt;eval_pred.csv&lt;/code&gt; contententi dati di validazione del modello.&lt;/p&gt;

&lt;h2 id=&quot;programmazione-del-modello&quot;&gt;Programmazione del modello&lt;/h2&gt;

&lt;p&gt;La programmazione del modello è confinata entro specifici file memorizzati all’interno della cartella &lt;code class=&quot;highlighter-rouge&quot;&gt;setup&lt;/code&gt;. In particolare, gli unici due punti dove inseriamo i nostri sviluppi custom sono:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;train&lt;/code&gt;: in questo file, all’interno della funzione omonima &lt;code class=&quot;highlighter-rouge&quot;&gt;train()&lt;/code&gt; è confinato il codice per: la lettura dei file di training e testing; la lettura dei parametri di configurazione; la costruzione del modello; l’addestramento e la serializzazione delle impostazioni (pesi e architettura). Nell’esempio fornito, si utilizza Keras per interfacciarsi a CNTK e creare una semplice rete neurale. Ovviamente, è possibile utilizzare qualsiasi libreria Python, istanziare più algoritmi ML/DL, etc.., per la creazione di modelli di qualsivoglia complessità;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;predictor.py&lt;/code&gt;: in questo file, all’interno della funzione &lt;code class=&quot;highlighter-rouge&quot;&gt;get_model()&lt;/code&gt; è confinato il codice per l’istanziazione del modello (a partire dai file dei pesi e dell’architettura creati con l’esecuzione di &lt;code class=&quot;highlighter-rouge&quot;&gt;train&lt;/code&gt;) e l’implementazione della funzione di predizione. Null’altro è richiesto.&lt;/p&gt;

&lt;h2 id=&quot;generazione-dellimmagine-e-caricamento-su-ecr&quot;&gt;Generazione dell’immagine e caricamento su ECR&lt;/h2&gt;

&lt;p&gt;Dopo aver verificato, in locale, il corretto funzionamento del container e del modello in esso incapsulato, possiamo generare (&lt;em&gt;build&lt;/em&gt;) una nuova immagine e spedirla (&lt;em&gt;push&lt;/em&gt;) al registro Docker ECR. Per questa operazione dobbiamo spostarci nella cartella base ed eseguire l’istruzione:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  ./build_and_push_to_ecr.sh cntkdemo-ecr-4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;dove &lt;code class=&quot;highlighter-rouge&quot;&gt;cntkdemo-ecr-4&lt;/code&gt; è un nome che ho arbitrariamente assegnato all’immagine.&lt;/p&gt;

&lt;p&gt;Possiamo visualizzare l’elenco delle immagini (sia in locale sia su ECR) digitando l’istruzione:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  docker images
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;configurazione-di-un-modello-e-creazione-dellartifact&quot;&gt;Configurazione di un modello e creazione dell’artifact&lt;/h2&gt;

&lt;p&gt;Abbandondiamo la finestra del &lt;code class=&quot;highlighter-rouge&quot;&gt;Terminal&lt;/code&gt; e accediamo al Jupyter su SageMaker. Quindi, spostiamoci nella cartella &lt;code class=&quot;highlighter-rouge&quot;&gt;CNTK_KERAS_SAGEMAKER/container/evaluation&lt;/code&gt;. In questa cartella sono precaricati tre notebook.&lt;/p&gt;

&lt;p&gt;Selezioniamo il notebook &lt;code class=&quot;highlighter-rouge&quot;&gt;HowToPrepareModel&lt;/code&gt;. Il notebook contiene le istruzioni per:&lt;/p&gt;

&lt;p&gt;il caricamento dei dataset di training e testing dalla cartella locale &lt;code class=&quot;highlighter-rouge&quot;&gt;context&lt;/code&gt; ad una cartella remota sullo storage S3&lt;label for=&quot;sh-id-s3&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sh-id-s3&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;&lt;a href=&quot;https://aws.amazon.com/it/s3/&quot;&gt;Amazon Simple Storage&lt;/a&gt; &lt;/span&gt; associato all’utenza che abbiamo usato per accedere a SageMaker;&lt;/p&gt;

&lt;p&gt;la predisposizione del container, attraverso l’impiego dell’interfaccia &lt;code class=&quot;highlighter-rouge&quot;&gt;sage.estimator.Estimator&lt;/code&gt;&lt;label for=&quot;sn-id-estimator&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sn-id-estimator&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;Consultare &lt;a href=&quot;http://sagemaker.readthedocs.io/en/latest/estimators.html&quot;&gt;Amazon SageMaker Python SDK&lt;/a&gt; per ulteriori dettagli sull’SDK Python per SageMaker. &lt;/span&gt; e avendo cura di specificare: il riferimento all’immagine precedentemente caricata su ECR; il tipo di istanza EC2 da attivare; il puntamento alla cartella su S3 creata e popolata al passo precedente;&lt;/p&gt;

&lt;p&gt;la configurazione dei parametri&lt;label for=&quot;sn-id-sagemakerjsonconf&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sn-id-sagemakerjsonconf&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;I parametri sono esattamente gli stessi che in locale abbiamo specificato all’interno del file &lt;code class=&quot;highlighter-rouge&quot;&gt;hyperparameters.json&lt;/code&gt;. SageMaker provvede automaticamente alla creazione di un file json analogo a quello che abbiamo usato per i nostri test in locale. &lt;/span&gt; del modello attraverso il metodo &lt;code class=&quot;highlighter-rouge&quot;&gt;set_hyperparameters&lt;/code&gt; dell’&lt;code class=&quot;highlighter-rouge&quot;&gt;Estimator&lt;/code&gt;;&lt;/p&gt;

&lt;p&gt;l’addestramento del modello attraverso l’invocazione del metodo &lt;code class=&quot;highlighter-rouge&quot;&gt;fit&lt;/code&gt; dell’&lt;code class=&quot;highlighter-rouge&quot;&gt;Estimator&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Al termine dell’addestramento, i file dei pesi e dell’architettura saranno automaticamente compressi nell’archivio &lt;code class=&quot;highlighter-rouge&quot;&gt;model.tar.gz&lt;/code&gt; che è salvato su S3. L’insieme dei file contenenti pesi e architettura è chiamato &lt;strong&gt;model artifact&lt;/strong&gt;. Possiamo ottenere l’indirizzo esteso del model artifact memorizzato su S3 eseguendo l’istruzione:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  estimator.model_data
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;incapsulare-il-modello-in-container-e-associare-un-endpoint&quot;&gt;Incapsulare il modello in container e associare un endpoint&lt;/h2&gt;

&lt;p&gt;Selezioniamo il notebook &lt;code class=&quot;highlighter-rouge&quot;&gt;HowToDeployModel&lt;/code&gt;. Il notebook contiene le istruzioni per:&lt;/p&gt;

&lt;p&gt;istanziare il modello partendo dal model artifact generato nella sezione precedente;&lt;/p&gt;

&lt;p&gt;assegnare il container ad un endpoint HTTPS;&lt;/p&gt;

&lt;p&gt;attivare l’endpoint (l’attivazione può richiedere qualche minuto).&lt;/p&gt;

&lt;h2 id=&quot;accedere-allendpoint&quot;&gt;Accedere all’endpoint&lt;/h2&gt;

&lt;p&gt;Selezioniamo il notebook &lt;code class=&quot;highlighter-rouge&quot;&gt;HowToInvokeModel&lt;/code&gt;. Il notebook contiene le istruzioni per:&lt;/p&gt;

&lt;p&gt;caricare i dati di validazione dal file locale &lt;code class=&quot;highlighter-rouge&quot;&gt;eval_data.csv&lt;/code&gt;;&lt;/p&gt;

&lt;p&gt;accedere all’endpoint HTTPS per invocare la funzione di predizione. L’accesso all’endpoint avviene attraverso il metodo &lt;code class=&quot;highlighter-rouge&quot;&gt;invoke_endpoint&lt;/code&gt; comodamente richiamabile attraverso il modulo &lt;code class=&quot;highlighter-rouge&quot;&gt;boto3&lt;/code&gt;&lt;label for=&quot;sh-id-boto3&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sh-id-boto3&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;&lt;a href=&quot;http://boto3.readthedocs.io/en/latest/&quot;&gt;boto3&lt;/a&gt; è l’SDK Python per l’accesso ai servizi AWS. &lt;/span&gt;. Il payload dell’invocazione è composto dai dati di validazione che abbiamo opportunamente letto e pre-trattato per l’invio (vedi passo precedente).&lt;/p&gt;

&lt;p&gt;Il notebook include istruzioni esemplificative per l’estrazione dei risultati dalla &lt;em&gt;response&lt;/em&gt; e la valutazione dell’accuratezza usando i dati &lt;em&gt;ground truth&lt;/em&gt; memorizzati in &lt;code class=&quot;highlighter-rouge&quot;&gt;eval_pred.csv&lt;/code&gt;, ma questi sono passaggi semplici.&lt;/p&gt;

&lt;p&gt;Buon divertimento con il vostro nuovo modello custom!&lt;/p&gt;
</description>
        <pubDate>Sun, 21 Jan 2018 12:56:00 -0500</pubDate>
        <link>https://ltoscano.github.com/articles/18/how-to-microsoft-cntk-keras-aws-sagemaker</link>
        <guid isPermaLink="true">https://ltoscano.github.com/articles/18/how-to-microsoft-cntk-keras-aws-sagemaker</guid>
        
        
        <category>post</category>
        
      </item>
    
      <item>
        <title>Intuitions on the fly on Blockchain</title>
        <description>&lt;p&gt;&lt;label for=&quot;mf-id-whatever&quot; class=&quot;margin-toggle&quot;&gt;⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;mf-id-whatever&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;img class=&quot;fullwidth&quot; src=&quot;/assets/img/blockchain.png&quot; /&gt;&lt;br /&gt;Image source: &lt;a href=&quot;https://icons8.com/&quot;&gt;Icons8&lt;/a&gt;. &lt;em&gt;Distributed under &lt;a href=&quot;https://creativecommons.org/licenses/by-nd/3.0/&quot;&gt;Creative Commons Attribution-NoDerivs 3.0 Unported.&lt;/a&gt;&lt;/em&gt;&lt;/span&gt;
An increasing number of articles suggest fascinating combinations of Blockchain and Machine Learning. It could be useful to introduce some intuitions about what is a blockchain, before venturing forth.&lt;/p&gt;

&lt;p&gt;In the 2008 &lt;a href=&quot;https://en.wikipedia.org/wiki/Bitcoin&quot;&gt;Bitcoin&lt;/a&gt; entered the market. It was a pioneering payment method and &lt;strong&gt;cryptocurrency&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The technology underlying Bitcoin is called &lt;strong&gt;Blockchain&lt;/strong&gt;. Nowadays Bitcoin is the most important implementation of Blockchain. However, in the last 2 years many opportunities have emerged and Blockchain has assumed a central role in different contexts.&lt;/p&gt;

&lt;p&gt;It is not simple to exactly explain how Blockchain works because it is a &lt;a href=&quot;https://bitsonblocks.net/2015/09/09/a-gentle-introduction-to-blockchain-technology/&quot;&gt;combination of different technologies&lt;/a&gt;. More appropriately, Blockchain is an &lt;strong&gt;ecosystem&lt;/strong&gt; where different technologies, approaches and theories converge.&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;Please continue to read the original post &lt;a href=&quot;https://ltoscano.github.io/apprendimentoautomatico-wpblog/en/introduction-to-bitcoin-intuitions/&quot;&gt;Intuitions on the fly on Blockchain&lt;/a&gt; on my old blog.&lt;/p&gt;
</description>
        <pubDate>Sun, 07 May 2017 17:04:01 -0400</pubDate>
        <link>https://ltoscano.github.com/articles/17/introduction-to-bitcoin-intuitions</link>
        <guid isPermaLink="true">https://ltoscano.github.com/articles/17/introduction-to-bitcoin-intuitions</guid>
        
        
        <category>post</category>
        
      </item>
    
      <item>
        <title>Hype cycle e Apprendimento Automatico: in che fase siamo?</title>
        <description>&lt;p&gt;&lt;label for=&quot;mf-id-whatever&quot; class=&quot;margin-toggle&quot;&gt;⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;mf-id-whatever&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;img class=&quot;fullwidth&quot; src=&quot;/assets/img/1118px-Gartner_Hype_Cycle.svg.png&quot; /&gt;&lt;br /&gt;Image source: &lt;a href=&quot;https://commons.wikimedia.org/wiki/File:Gartner_Hype_Cycle.svg&quot;&gt;Wikimedia&lt;/a&gt;. &lt;em&gt;Distributed under &lt;a href=&quot;https://en.wikipedia.org/wiki/GNU_Free_Documentation_License&quot;&gt;GNU Free Documentation License&lt;/a&gt;&lt;/em&gt;&lt;/span&gt;
Ogni trend tecnologico si sviluppa attraverso una successione di fasi che ne caratterizza il processo di maturazione: dall’emersione alla sua accettazione. Tale processo è sempre accompagnato da un “&lt;strong&gt;buzzing tecnologico&lt;/strong&gt;” che solitamente esplode nelle fasi iniziali di maggiore “illusione” per poi rimodularsi progressivamente in funzione dell’accettazione da parte del pubblico. Semplificando, il ben noto &lt;a href=&quot;https://en.wikipedia.org/wiki/Hype_cycle&quot;&gt;hype cycle&lt;/a&gt; (&lt;strong&gt;ciclo dell’esagerazione&lt;/strong&gt;) di Gartner potrebbe essere considerato come una metodologia che ci aiuta a riassumere graficamente lo stato del buzzing che avvolge una grande varietà di trend tecnologici.&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;Continua a leggere l’articolo originale &lt;a href=&quot;https://ltoscano.github.io/apprendimentoautomatico-wpblog/hype-cycle-e-apprendimento-automatico-in-che-fase-siamo/&quot;&gt;Hype cycle e Apprendimento Automatico: in che fase siamo?&lt;/a&gt; sul mio vecchio blog.&lt;/p&gt;
</description>
        <pubDate>Fri, 07 Apr 2017 17:04:01 -0400</pubDate>
        <link>https://ltoscano.github.com/articles/17/hype-cycle-e-apprendimento-automatico-in-che-fase-siamo</link>
        <guid isPermaLink="true">https://ltoscano.github.com/articles/17/hype-cycle-e-apprendimento-automatico-in-che-fase-siamo</guid>
        
        
        <category>post</category>
        
      </item>
    
      <item>
        <title>Emotions Detection Via Facial Expressions with python &amp; OpenCV</title>
        <description>&lt;p&gt;&lt;label for=&quot;mf-id-whatever&quot; class=&quot;margin-toggle&quot;&gt;⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;mf-id-whatever&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;img class=&quot;fullwidth&quot; src=&quot;/assets/img/Universal_emotions7.jpg&quot; /&gt;&lt;br /&gt;&lt;/span&gt;
In this tutorial I aim to quench a subset of your machine learning thirst; And for what other reason would you be here? This tutorial is based on training a computer to recognize not just your face but the emotion expressed on it. How cool is that? Imagine walking into your home after a long day of work, and your computer immediately knows what kind of therapeutic music to play based on how you are feeling, or when you are driving the car onboard computer is able to assess your ability to drive based on your emotions.&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;Please continue to read the original post &lt;a href=&quot;https://ltoscano.github.io/apprendimentoautomatico-wpblog/en/emotions-detection-via-facial-expressions-with-python-opencv/&quot;&gt;Emotions Detection Via Facial Expressions with python &amp;amp; OpenCV&lt;/a&gt; on my old blog.&lt;/p&gt;
</description>
        <pubDate>Sun, 01 Jan 2017 17:04:01 -0500</pubDate>
        <link>https://ltoscano.github.com/articles/17/emotions-detection-via-facial-expressions-with-python-opencv</link>
        <guid isPermaLink="true">https://ltoscano.github.com/articles/17/emotions-detection-via-facial-expressions-with-python-opencv</guid>
        
        
        <category>post</category>
        
      </item>
    
      <item>
        <title>Introduction to gradient-boosted trees and XGBoost hyperparameters tuning (with python)</title>
        <description>&lt;p&gt;&lt;label for=&quot;mf-id-whatever&quot; class=&quot;margin-toggle&quot;&gt;⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;mf-id-whatever&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;img class=&quot;fullwidth&quot; src=&quot;/assets/img/ensembletree.png&quot; /&gt;&lt;br /&gt;&lt;/span&gt;
XGBoost model is a supervised machine learning algorithm that takes in the training data and constructs a model that predicts the outcome of new data instances.&lt;/p&gt;

&lt;p&gt;XGBoost has gained a lot of popularity in the machine learning community due to its ability to train versatile model with speed and quality performance. It’s an implementation of &lt;strong&gt;gradient boosted decision trees&lt;/strong&gt; which are constructed for speed and performance.&lt;/p&gt;

&lt;p&gt;For an in-depth introduction visit this link for &lt;a href=&quot;http://xgboost.readthedocs.io/en/latest/model.html&quot;&gt;more technical details&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here we cover a gentle introduction of XGBoost model using python scikit-learn package.&lt;/p&gt;

&lt;p&gt;By the end of this tutorial you will have learnt:&lt;/p&gt;

&lt;p&gt;XGBoost installation for python use&lt;/p&gt;

&lt;p&gt;XGBoost data preparation and model training&lt;/p&gt;

&lt;p&gt;XGBoost model prediction&lt;/p&gt;

&lt;p&gt;XGBoost hyperparameters tuning&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;Please continue to read the original post &lt;a href=&quot;https://ltoscano.github.io/apprendimentoautomatico-wpblog/en/introduction-to-gradient-boosted-trees-and-xgboost-hyperparameters-tuning-with-python/&quot;&gt;Introduction to gradient-boosted trees and XGBoost hyperparameters tuning (with python)&lt;/a&gt; on my old blog.&lt;/p&gt;
</description>
        <pubDate>Sun, 01 Jan 2017 10:04:01 -0500</pubDate>
        <link>https://ltoscano.github.com/articles/17/introduction-to-gradient-boosted-trees-and-xgboost-hyperparameters-tuning-with-python</link>
        <guid isPermaLink="true">https://ltoscano.github.com/articles/17/introduction-to-gradient-boosted-trees-and-xgboost-hyperparameters-tuning-with-python</guid>
        
        
        <category>post</category>
        
      </item>
    
      <item>
        <title>Introduction to decision trees with BigML: a step by step guide </title>
        <description>&lt;p&gt;&lt;label for=&quot;mf-id-whatever&quot; class=&quot;margin-toggle&quot;&gt;⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;mf-id-whatever&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;img class=&quot;fullwidth&quot; src=&quot;/assets/img/bigml.png&quot; /&gt;&lt;br /&gt;&lt;/span&gt;
The discussion on machine learning is the buzz word in the current tech tectonic waves. It’s all amber-hot as the machines are nearly on the verge of learning to do things and react to the environment around them in more &lt;a href=&quot;https://www.newscientist.com/article/2110522-googles-neural-networks-invent-their-own-encryption/&quot;&gt;human-like-unsupervised-design&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Machine learning is a field of neuro-computational studies, in which scientists work towards instilling learning capabilities in a computer memory. This is all possible through implementation of a set of supervised or unsupervised rules referred to as algorithms. The most popular machine learning algorithms are artificial neural networks, support vector machines, k-nearest neighbors and &lt;strong&gt;decision trees&lt;/strong&gt;. We will discuss the decision trees in this context.&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;Please continue to read the original post &lt;a href=&quot;https://ltoscano.github.io/apprendimentoautomatico-wpblog/en/introduction-to-decision-trees-with-bigml-a-step-by-step-guide/&quot;&gt;Introduction to decision trees with BigML: a step by step guide&lt;/a&gt; on my old blog.&lt;/p&gt;
</description>
        <pubDate>Wed, 07 Dec 2016 10:04:01 -0500</pubDate>
        <link>https://ltoscano.github.com/articles/16/introduction-to-decision-trees-with-bigml-a-step-by-step-guide</link>
        <guid isPermaLink="true">https://ltoscano.github.com/articles/16/introduction-to-decision-trees-with-bigml-a-step-by-step-guide</guid>
        
        
        <category>post</category>
        
      </item>
    
      <item>
        <title>Machine Learning: the best cheat sheets in one page</title>
        <description>&lt;p&gt;&lt;label for=&quot;mf-id-whatever&quot; class=&quot;margin-toggle&quot;&gt;⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;mf-id-whatever&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;img class=&quot;fullwidth&quot; src=&quot;/assets/img/human-1211467_1280-e1480808939595.png&quot; /&gt;&lt;br /&gt;&lt;/span&gt;
Squeezed into a set of short tips and schemes, a cheat sheet is not only a source for visual inspiration but also a quick way to learn something new, as well as to refresh your knowledge about any particular subject.&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;Please continue to read the original post &lt;a href=&quot;https://ltoscano.github.io/apprendimentoautomatico-wpblog/en/machine-learning-best-cheat-sheets-one-page/&quot;&gt;Machine Learning: the best cheat sheets in one page&lt;/a&gt; on my old blog.&lt;/p&gt;
</description>
        <pubDate>Wed, 07 Dec 2016 09:04:01 -0500</pubDate>
        <link>https://ltoscano.github.com/articles/16/machine-learning-best-cheat-sheets-one-page</link>
        <guid isPermaLink="true">https://ltoscano.github.com/articles/16/machine-learning-best-cheat-sheets-one-page</guid>
        
        
        <category>post</category>
        
      </item>
    
      <item>
        <title>Understanding Apache Ecosystem: stream processing</title>
        <description>&lt;p&gt;&lt;label for=&quot;mf-id-whatever&quot; class=&quot;margin-toggle&quot;&gt;⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;mf-id-whatever&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;img class=&quot;fullwidth&quot; src=&quot;/assets/img/apache-ecosystem.jpg&quot; /&gt;&lt;br /&gt;&lt;/span&gt;
In this article I will show how a normal big data/machine learning project progresses, taking in account the &lt;strong&gt;stream processing&lt;/strong&gt; and analysis part. I will try to functionally position a wide variety of Apache projects such as Sqoop, Flume, Kafka, Hadoop, Storm, Spark, Samza, Flink, Beam, Oozie, Thrift.&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;Please continue to read the original post &lt;a href=&quot;https://ltoscano.github.io/apprendimentoautomatico-wpblog/en/stream-processing-and-analysis-to-move-within-the-apache-ecosystem/&quot;&gt;Understanding Apache Ecosystem: stream processing&lt;/a&gt; on my old blog.&lt;/p&gt;
</description>
        <pubDate>Mon, 07 Nov 2016 15:04:01 -0500</pubDate>
        <link>https://ltoscano.github.com/articles/16/stream-processing-and-analysis-to-move-within-the-apache-ecosystem</link>
        <guid isPermaLink="true">https://ltoscano.github.com/articles/16/stream-processing-and-analysis-to-move-within-the-apache-ecosystem</guid>
        
        
        <category>post</category>
        
      </item>
    
      <item>
        <title>A gentle introduction to TensorFlow with python (and RNN)</title>
        <description>&lt;p&gt;&lt;label for=&quot;mf-id-whatever&quot; class=&quot;margin-toggle&quot;&gt;⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;mf-id-whatever&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;img class=&quot;fullwidth&quot; src=&quot;/assets/img/tensorflowpython.png&quot; /&gt;&lt;br /&gt;&lt;/span&gt;
My quick and dirty introduction to TensorFlow.&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;Please continue to read the original post &lt;a href=&quot;https://ltoscano.github.io/apprendimentoautomatico-wpblog/en/gentle-introduction-to-tensorflow-with-python-and-rnn/&quot;&gt;A gentle introduction to TensorFlow with python (and RNN)&lt;/a&gt; on my old blog.&lt;/p&gt;
</description>
        <pubDate>Mon, 07 Nov 2016 12:04:01 -0500</pubDate>
        <link>https://ltoscano.github.com/articles/16/gentle-introduction-to-tensorflow-with-python-and-rnn</link>
        <guid isPermaLink="true">https://ltoscano.github.com/articles/16/gentle-introduction-to-tensorflow-with-python-and-rnn</guid>
        
        
        <category>post</category>
        
      </item>
    
      <item>
        <title>Riconoscimento vocale e analisi di testo non strutturato con Watson Developer Cloud Python SDK</title>
        <description>&lt;p&gt;&lt;label for=&quot;mf-id-whatever&quot; class=&quot;margin-toggle&quot;&gt;⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;mf-id-whatever&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;img class=&quot;fullwidth&quot; src=&quot;/assets/img/blue-robot-vector-art-e1478100652986.png&quot; /&gt;&lt;br /&gt;&lt;/span&gt;
In questo post illustro come: estrarre &lt;strong&gt;tracce audio&lt;/strong&gt; da filmati (usando, per esempio, YouTube), eseguire una &lt;strong&gt;conversione del parlato&lt;/strong&gt; in testo (&lt;em&gt;speech to text&lt;/em&gt;), estrarre &lt;strong&gt;conoscenza dal testo non strutturato della trascrizione&lt;/strong&gt;.&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;Continua a leggere l’articolo originale &lt;a href=&quot;https://ltoscano.github.io/apprendimentoautomatico-wpblog/riconoscimento-vocale-analisi-testo-watson-developer-cloud-python-sdk/&quot;&gt;Riconoscimento vocale e analisi di testo non strutturato con Watson Developer Cloud Python SDK&lt;/a&gt; sul mio vecchio blog.&lt;/p&gt;
</description>
        <pubDate>Mon, 07 Nov 2016 11:04:01 -0500</pubDate>
        <link>https://ltoscano.github.com/articles/16/riconoscimento-vocale-analisi-testo-watson-developer-cloud-python-sdk</link>
        <guid isPermaLink="true">https://ltoscano.github.com/articles/16/riconoscimento-vocale-analisi-testo-watson-developer-cloud-python-sdk</guid>
        
        
        <category>post</category>
        
      </item>
    
  </channel>
</rss>
